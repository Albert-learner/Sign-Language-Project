{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabblee/anaconda3/envs/AI/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x Shape : torch.Size([8, 1, 40, 8])\n",
      "conv1 Shape : torch.Size([8, 3, 37, 5])\n",
      "conv2 Shape : torch.Size([8, 3, 10, 2])\n",
      "After Flatten, x Shape : torch.Size([8, 60])\n",
      "fc1 Shape : torch.Size([8, 23])\n",
      "None\n",
      "Input x Shape : torch.Size([2, 1, 40, 8])\n",
      "conv1 Shape : torch.Size([2, 3, 37, 5])\n",
      "conv2 Shape : torch.Size([2, 3, 10, 2])\n",
      "After Flatten, x Shape : torch.Size([2, 60])\n",
      "fc1 Shape : torch.Size([2, 23])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class Prev_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Prev_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 3, \n",
    "                               kernel_size = 8, stride = 1, padding = 2,\n",
    "                               bias = True)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 3, out_channels = 3,\n",
    "                               kernel_size = 1, stride = 4, padding = 0,\n",
    "                               bias = True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(60, 23)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print('Input x Shape :', x.shape)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        print('conv1 Shape :', x.shape)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        print('conv2 Shape :', x.shape)\n",
    "        x = nn.Flatten()(x)\n",
    "        print('After Flatten, x Shape :', x.shape)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        print('fc1 Shape :', x.shape)\n",
    "        \n",
    "        # return x\n",
    "    \n",
    "\n",
    "input_train_tensor = torch.randn((8, 1, 40, 8))\n",
    "input_test_tensor = torch.randn((2, 1, 40, 8))\n",
    "\n",
    "prev_model = Prev_Net()\n",
    "print(prev_model.forward(input_train_tensor))\n",
    "print(prev_model.forward(input_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Shape : torch.Size([8, 432])\n",
      "x Shape : torch.Size([8, 23])\n",
      "tensor([[-0.0542, -0.1766, -0.0861,  0.0355,  0.0779,  0.1315,  0.0462, -0.1328,\n",
      "          0.0100, -0.2626,  0.0442, -0.0286, -0.0247,  0.0737,  0.1067,  0.0195,\n",
      "         -0.0442, -0.0210, -0.0686,  0.0200,  0.0370,  0.0497,  0.1161],\n",
      "        [-0.0970, -0.1987, -0.1014,  0.0721,  0.1071,  0.1483,  0.0377, -0.1134,\n",
      "         -0.0071, -0.2881,  0.0293, -0.0178, -0.0387,  0.0483,  0.1054,  0.0830,\n",
      "         -0.0488, -0.0014, -0.0645,  0.0051,  0.0503,  0.0438,  0.0994],\n",
      "        [-0.0299, -0.1826, -0.0915,  0.0724,  0.0983,  0.1417,  0.0734, -0.1151,\n",
      "          0.0147, -0.2852,  0.0249, -0.0257, -0.0138,  0.0577,  0.0840,  0.0520,\n",
      "         -0.0604,  0.0035, -0.0889,  0.0114,  0.0364,  0.0648,  0.1185],\n",
      "        [-0.0430, -0.1672, -0.1233,  0.0639,  0.1061,  0.1317,  0.0412, -0.1210,\n",
      "          0.0110, -0.2865,  0.0406, -0.0145, -0.0350,  0.0605,  0.1070,  0.0472,\n",
      "         -0.0570,  0.0111, -0.0606,  0.0029,  0.0419,  0.0853,  0.1358],\n",
      "        [-0.0337, -0.1627, -0.0759,  0.0675,  0.1056,  0.1121,  0.0626, -0.1237,\n",
      "          0.0180, -0.2855,  0.0634, -0.0384, -0.0077,  0.0537,  0.0595,  0.0293,\n",
      "         -0.0809,  0.0126, -0.0645,  0.0237,  0.0421,  0.0821,  0.1320],\n",
      "        [-0.0243, -0.1574, -0.0576,  0.0383,  0.0639,  0.1562,  0.0706, -0.1272,\n",
      "          0.0213, -0.2605,  0.0336, -0.0450,  0.0127,  0.0515,  0.0572,  0.0614,\n",
      "         -0.0452, -0.0208, -0.0947,  0.0248,  0.0239,  0.0470,  0.1171],\n",
      "        [-0.0530, -0.1904, -0.0805,  0.1018,  0.1080,  0.1309,  0.0582, -0.1223,\n",
      "          0.0187, -0.2681,  0.0324, -0.0366, -0.0272,  0.0254,  0.0673,  0.0780,\n",
      "         -0.0551,  0.0188, -0.0485,  0.0179,  0.0149,  0.0735,  0.1301],\n",
      "        [-0.0409, -0.1650, -0.0885,  0.0517,  0.1119,  0.1637,  0.0579, -0.1033,\n",
      "          0.0317, -0.2833,  0.0389, -0.0135, -0.0007,  0.0717,  0.0916,  0.0558,\n",
      "         -0.0642, -0.0104, -0.0793,  0.0188,  0.0475,  0.0715,  0.1372]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "x Shape : torch.Size([2, 432])\n",
      "x Shape : torch.Size([2, 23])\n",
      "tensor([[-0.0502, -0.1789, -0.0930,  0.0502,  0.0985,  0.1636,  0.0718, -0.1171,\n",
      "          0.0069, -0.2912,  0.0333, -0.0396, -0.0126,  0.1012,  0.0868,  0.0243,\n",
      "         -0.0498, -0.0217, -0.0557,  0.0373,  0.0477,  0.0591,  0.1359],\n",
      "        [-0.0311, -0.1914, -0.0922,  0.0680,  0.0843,  0.1371,  0.0576, -0.1275,\n",
      "          0.0005, -0.2824,  0.0323, -0.0409, -0.0240,  0.0637,  0.0900,  0.0526,\n",
      "         -0.0677, -0.0064, -0.0722,  0.0058,  0.0295,  0.0669,  0.1073]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        # Mine that followed by Sun's Net\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 3,\n",
    "                               kernel_size = 5, stride = 1,\n",
    "                               padding = 0, bias = True)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 3, out_channels = 3,\n",
    "                               kernel_size = 1, stride = 1,\n",
    "                               padding = 0, bias = True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(432, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 23)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # # Mine that followed by Sun's Net3\n",
    "        # self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 3,\n",
    "        #                        kernel_size = 5, stride = 1, padding = 2,\n",
    "        #                        bias = True)\n",
    "        # self.conv2 = nn.Conv2d(in_channels = 3, out_channels = 3,\n",
    "        #                        kernel_size = 3, stride = 4, padding = 0,\n",
    "        #                        bias = True)\n",
    "        \n",
    "        # self.relu = nn.ReLU()\n",
    "\n",
    "        # self.fc1 = nn.Linear(60, 48)\n",
    "        # self.fc2 = nn.Linear(48, 32)\n",
    "        # self.fc3 = nn.Linear(32, 23)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = nn.Flatten()(x)\n",
    "        print('x Shape :', x.shape)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        print('x Shape :', x.shape)\n",
    "\n",
    "        return x\n",
    "    \n",
    "input_train_tensor = torch.randn((8, 1, 40, 8))\n",
    "input_test_tensor = torch.randn((2, 1, 40, 8))\n",
    "\n",
    "lenet5 = LeNet5()\n",
    "print(lenet5.forward(input_train_tensor))\n",
    "print(lenet5.forward(input_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_output Shape : torch.Size([16, 64, 40, 8])\n",
      "conv2 Shape : torch.Size([16, 64, 40, 8])\n",
      "Maxpool 2d_1 Shape : torch.Size([16, 64, 31, 7])\n",
      "conv3 output Shape : torch.Size([16, 128, 31, 7])\n",
      "conv4 output Shape : torch.Size([16, 128, 31, 7])\n",
      "Maxpool 2d_2 Shape : torch.Size([16, 128, 22, 6])\n",
      "conv5 output Shape : torch.Size([16, 256, 22, 6])\n",
      "conv6 output Shape : torch.Size([16, 256, 22, 6])\n",
      "conv7 output Shape : torch.Size([16, 256, 22, 6])\n",
      "Maxpool 2d_3 Shape : torch.Size([16, 256, 13, 5])\n",
      "conv8 output Shape : torch.Size([16, 512, 13, 5])\n",
      "conv9 output Shape : torch.Size([16, 512, 13, 5])\n",
      "conv10 output Shape : torch.Size([16, 512, 13, 5])\n",
      "Maxpool 2d_4 Shape : torch.Size([16, 512, 4, 4])\n",
      "Average Pooling output Shape : torch.Size([16, 512, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "input_train_tensor = torch.randn((16, 1, 40, 8))\n",
    "input_test_tensor = torch.randn((1, 1, 40, 8))\n",
    "\n",
    "relu = nn.ReLU(inplace = True)\n",
    "conv1 = nn.Conv2d(1, 64, kernel_size = 3, padding = 1)\n",
    "conv1_output = relu(conv1(input_train_tensor))\n",
    "print('conv1_output Shape :', conv1_output.shape)\n",
    "conv2 = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\n",
    "conv2_output = relu(conv2(conv1_output))\n",
    "print('conv2 Shape :', conv2_output.shape)\n",
    "maxpool2d_1 = nn.MaxPool2d(kernel_size = (10, 2), stride = 1)\n",
    "maxpool2d_1_output = maxpool2d_1(conv2_output)\n",
    "print('Maxpool 2d_1 Shape :', maxpool2d_1_output.shape)\n",
    "\n",
    "conv3 = nn.Conv2d(64, 128, kernel_size = 3, padding = 1)\n",
    "conv3_output = relu(conv3(maxpool2d_1_output))\n",
    "print('conv3 output Shape :', conv3_output.shape)\n",
    "conv4 = nn.Conv2d(128, 128, kernel_size = 3, padding = 1)\n",
    "conv4_output = conv4(conv3_output)\n",
    "print('conv4 output Shape :', conv4_output.shape)\n",
    "maxpool2d_2 = nn.MaxPool2d(kernel_size = (10, 2), stride = 1)\n",
    "maxpool2d_2_output = maxpool2d_2(conv4_output)\n",
    "print('Maxpool 2d_2 Shape :', maxpool2d_2_output.shape)\n",
    "\n",
    "conv5 = nn.Conv2d(128, 256, kernel_size = 3, padding = 1)\n",
    "conv5_output = relu(conv5(maxpool2d_2_output))\n",
    "print('conv5 output Shape :', conv5_output.shape)\n",
    "conv6 = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\n",
    "conv6_output = relu(conv6(conv5_output))\n",
    "print('conv6 output Shape :', conv6_output.shape)\n",
    "conv7 = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\n",
    "conv7_output = relu(conv7(conv6_output))\n",
    "print('conv7 output Shape :', conv7_output.shape)\n",
    "maxpoo12d_3 = nn.MaxPool2d(kernel_size = (10, 2), stride = 1)\n",
    "maxpool2d_3_output = maxpoo12d_3(conv7_output)\n",
    "print('Maxpool 2d_3 Shape :', maxpool2d_3_output.shape)\n",
    "\n",
    "conv8 = nn.Conv2d(256, 512, kernel_size = 3, padding = 1)\n",
    "conv8_output = relu(conv8(maxpool2d_3_output))\n",
    "print('conv8 output Shape :', conv8_output.shape)\n",
    "conv9 = nn.Conv2d(512, 512,kernel_size = 3, padding = 1)\n",
    "conv9_output = relu(conv9(conv8_output))\n",
    "print('conv9 output Shape :', conv9_output.shape)\n",
    "conv10 = nn.Conv2d(512, 512, kernel_size = 3, padding = 1)\n",
    "conv10_output = relu(conv10(conv9_output))\n",
    "print('conv10 output Shape :', conv10_output.shape)\n",
    "maxpool2d_4 = nn.MaxPool2d(kernel_size = (10, 2), stride = 1)\n",
    "maxpool2d_4_output = maxpool2d_4(conv10_output)\n",
    "print('Maxpool 2d_4 Shape :', maxpool2d_4_output.shape)\n",
    "\n",
    "avgpool = nn.AdaptiveAvgPool2d((5, 1))\n",
    "avgpool_output = avgpool(maxpool2d_4_output)\n",
    "print('Average Pooling output Shape :', avgpool_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.7716e-03, -1.8743e-02,  2.2647e-02, -7.6124e-03,  2.0611e-02,\n",
      "          1.2198e-03,  9.6716e-03,  7.4640e-03, -4.7795e-03,  6.0839e-03,\n",
      "         -1.1102e-03, -8.4317e-03,  1.2961e-02, -1.4063e-03,  1.3204e-02,\n",
      "          1.2649e-03,  1.2984e-02, -2.1965e-02,  2.5754e-04,  1.6447e-02,\n",
      "          1.3513e-02,  1.2647e-02,  2.9681e-02],\n",
      "        [ 6.7494e-03, -1.1254e-02,  2.8570e-02, -3.2952e-03,  1.6568e-02,\n",
      "          1.5207e-02,  1.2577e-03,  1.4717e-02,  5.4799e-03,  1.2935e-02,\n",
      "         -5.9499e-03, -3.1816e-03,  8.2236e-03,  4.2149e-03,  8.2258e-03,\n",
      "         -3.8099e-03,  1.3052e-02, -1.9524e-02,  2.9810e-03,  1.3051e-02,\n",
      "          8.8034e-03,  2.6401e-02,  1.2587e-02],\n",
      "        [ 5.6904e-03, -1.0183e-02,  1.7786e-02, -5.0473e-03,  1.8218e-02,\n",
      "          4.5804e-03,  2.5791e-03,  1.4287e-02, -4.6805e-03,  1.9868e-03,\n",
      "         -1.5271e-02, -6.0977e-03,  1.7374e-02, -7.1546e-04,  1.2858e-02,\n",
      "          3.6543e-03,  6.5814e-03, -1.3131e-02,  1.0505e-03,  9.9008e-03,\n",
      "          1.0528e-02,  1.0056e-02,  2.2211e-02],\n",
      "        [ 6.7363e-03, -5.8125e-03,  3.0702e-02, -8.7321e-03,  2.1691e-02,\n",
      "          1.2641e-02,  3.3708e-03,  7.7949e-03,  5.7745e-03, -8.9297e-04,\n",
      "         -5.7566e-03, -1.0648e-02,  2.0133e-02,  8.4391e-03,  1.3143e-02,\n",
      "          8.1752e-03,  7.6677e-03, -1.9986e-02,  5.9401e-03,  1.5702e-02,\n",
      "          1.0036e-02,  6.8308e-03,  1.8251e-02],\n",
      "        [ 2.9308e-03, -2.1831e-02,  2.2876e-02, -9.1259e-03,  3.4651e-02,\n",
      "          1.1778e-02,  1.1303e-02,  1.7959e-02,  2.4144e-03,  4.5142e-03,\n",
      "         -8.1128e-04,  1.1445e-02,  1.5273e-02, -3.5581e-03,  1.1102e-02,\n",
      "          3.4271e-03,  7.3744e-03, -1.5199e-02,  4.4034e-03,  1.3564e-02,\n",
      "          1.4676e-02,  1.1937e-02,  2.8241e-02],\n",
      "        [ 9.7467e-03, -1.9662e-02,  2.0717e-02, -1.3494e-02,  2.3592e-02,\n",
      "          1.5952e-02,  5.6205e-03,  9.0875e-03,  5.0256e-03,  5.1640e-03,\n",
      "         -7.6063e-03, -4.4158e-04,  9.0079e-03,  7.3915e-03,  1.6656e-02,\n",
      "          8.7158e-03,  7.7711e-03, -1.1223e-02,  2.3296e-03,  5.3854e-03,\n",
      "          6.8731e-03,  1.4104e-02,  2.1242e-02],\n",
      "        [ 5.7191e-03, -1.0830e-02,  2.9975e-02, -9.9555e-03,  3.4608e-02,\n",
      "          1.0789e-02,  1.0091e-02,  2.1980e-02,  4.4437e-03,  1.4403e-02,\n",
      "         -3.0642e-03,  1.8660e-03,  1.3597e-02,  8.3706e-03,  1.3996e-02,\n",
      "          1.3190e-03,  1.3725e-02, -7.9224e-03,  3.2731e-03,  9.5324e-03,\n",
      "          1.2005e-02,  8.9180e-03,  2.0310e-02],\n",
      "        [ 8.8186e-03, -1.3455e-02,  3.2417e-02, -4.9377e-03,  2.9031e-02,\n",
      "          1.7810e-02,  2.3131e-02,  1.5136e-02,  3.7117e-03,  1.7894e-02,\n",
      "         -1.0987e-02, -8.4963e-05,  1.4688e-02,  6.2865e-03,  7.7874e-03,\n",
      "          1.2130e-02,  2.0815e-03, -1.0597e-02, -1.6639e-03,  1.3256e-02,\n",
      "          1.9624e-03,  7.3012e-03,  2.4639e-02]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0043, -0.0152,  0.0228, -0.0116,  0.0201,  0.0106,  0.0091,  0.0108,\n",
      "          0.0037, -0.0078, -0.0090,  0.0087,  0.0111, -0.0023,  0.0202, -0.0050,\n",
      "          0.0101, -0.0144, -0.0020,  0.0176,  0.0100,  0.0234,  0.0180],\n",
      "        [ 0.0071, -0.0168,  0.0257, -0.0023,  0.0169,  0.0144,  0.0002,  0.0099,\n",
      "         -0.0023,  0.0075, -0.0037,  0.0002,  0.0182, -0.0067,  0.0134,  0.0066,\n",
      "          0.0048, -0.0195, -0.0074,  0.0040, -0.0028,  0.0191,  0.0227]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class VGGNet16(nn.Module):\n",
    "    def __init__(self, num_classes=23):\n",
    "        super(VGGNet16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=1, stride=1),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((5, 1))  # Adjust output size based on your needs\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 5 * 1, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "input_train_tensor = torch.randn((8, 1, 40, 8))\n",
    "input_test_tensor = torch.randn((2, 1, 40, 8))\n",
    "vggnet16 = VGGNet16()\n",
    "print(vggnet16.forward(input_train_tensor))\n",
    "print(vggnet16.forward(input_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.conv1 Shape : torch.Size([1, 3, 5, 8])\n",
      "self.bn1 Shape : torch.Size([1, 3, 5, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1485,  0.1064, -0.2413,  0.0149,  0.0030,  0.2558,  0.1591, -0.1034,\n",
       "          0.1011,  0.0836, -0.2440,  0.0626,  0.3262, -0.0482, -0.0430, -0.2383,\n",
       "          0.0359,  0.0885, -0.0175,  0.2931, -0.1469,  0.1192,  0.0698]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += self.downsample(residual)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(3)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.layer1 = self._make_layer(BasicBlock, 3, 3, stride=1)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 3, 3, stride=4)\n",
    "\n",
    "        self.fc1 = nn.Linear(12, 48)\n",
    "        self.fc2 = nn.Linear(48, 32)\n",
    "        self.fc3 = nn.Linear(32, 23)\n",
    "\n",
    "    def _make_layer(self, block, in_channels, out_channels, stride):\n",
    "        layers = []\n",
    "        layers.append(block(in_channels, out_channels, stride))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        print('self.conv1 Shape :', x.shape)\n",
    "        x = self.bn1(x)\n",
    "        print('self.bn1 Shape :', x.shape)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "input_tensor = torch.randn((1, 1, 5, 8))\n",
    "resnet_model = ResNet()\n",
    "resnet_model.forward(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(4, 4), bias=False)\n",
      "        (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=60, out_features=48, bias=True)\n",
      "  (fc2): Linear(in_features=48, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=23, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet_model = ResNet()\n",
    "state_dict_path = \"/home/jabblee/Desktop/CRC_collections/CRC/output/23_state_dict.pt\"\n",
    "    # state_dict_path = \"/home/sun/Desktop/CRC/output/model1/28_state_dict_model.pt\"\n",
    "\n",
    "resnet_model.load_state_dict(torch.load(state_dict_path))\n",
    "print(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [40, 8]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1042447/1393437743.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtorch_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_test_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1042447/3921086992.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'self.conv1 Shape :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [40, 8]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "resnet_model = resnet_model.cuda()\n",
    "resnet_model.eval()\n",
    "\n",
    "raw_test_data = torch.Tensor([3007, 3829, 3558, 2387, 3127, 109, -2, 11])\n",
    "test_min = np.array([1227., 1227., 1227., 1227., 1227., -179, -82, -177])\n",
    "test_max = np.array([4095., 4095., 4095., 4095., 4095., 179, 84, 179])\n",
    "\n",
    "test_data = (raw_test_data - test_min) / (test_max - test_min)\n",
    "\n",
    "if test_data.shape == (8,):\n",
    "    test_data = test_data.reshape((1, 8))\n",
    "\n",
    "if len(test_data) <= 40:\n",
    "    test_data = np.append(test_data, np.zeros((40 - len(test_data), 8)), axis = 0)\n",
    "\n",
    "\n",
    "torch_test_data = torch.from_numpy(test_data).cuda().float()\n",
    "\n",
    "pred = resnet_model(torch_test_data)\n",
    "class_idx = torch.argmax(pred, 1)\n",
    "print(int(class_idx.item()), pred.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
